{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bz2\n",
    "import sqlite3\n",
    "import difflib\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import scipy.stats\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import sklearn.calibration\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import math\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3 data loaded in 0:00:19.056884.\n",
      "Features data loaded in 0:01:30.916610.\n"
     ]
    }
   ],
   "source": [
    "raw_data_dir = \"/export/scratch2/wiki_data\"\n",
    "derived_data_dir = os.path.join('/export/scratch2/levon003/repos/wiki-ores-feedback', \"data\", \"derived\")\n",
    "stub_history_dir = os.path.join(derived_data_dir, 'stub-history-all-revisions')\n",
    "revision_sample_dir = os.path.join(derived_data_dir, 'revision_sample')\n",
    "working_dir = os.path.join(derived_data_dir, 'audit')\n",
    "\n",
    "# ### Data loading and cleaning\n",
    "# read in the sample dataframe\n",
    "s = datetime.now()\n",
    "revision_sample_dir = os.path.join(derived_data_dir, 'revision_sample')\n",
    "sample3_filepath = os.path.join(revision_sample_dir, 'sample3_all.pkl')\n",
    "rev_df = pd.read_pickle(sample3_filepath)\n",
    "print(f\"Sample 3 data loaded in {datetime.now() - s}.\")\n",
    "\n",
    "# Load the features (2020-08-01 tsv file)\n",
    "s = datetime.now()\n",
    "labeled_revs_dir = os.path.join(derived_data_dir, 'labeled-revs')\n",
    "sample3_features_dir = os.path.join(labeled_revs_dir, 'sample3-features')\n",
    "sample3_damaging_filepath = os.path.join(sample3_features_dir, 'sample3.damaging.2020-08-01T05:40:00Z.tsv')\n",
    "features_df = pd.read_csv(sample3_damaging_filepath, sep='\\t', header=0)\n",
    "print(f\"Features data loaded in {datetime.now() - s}.\")\n",
    "\n",
    "# drop the useless 'damaging' column (it is auto-generated)\n",
    "features_df = features_df.drop(columns='damaging')\n",
    "\n",
    "# load the rev_ids that correspond to the feature data\n",
    "revid_filepath = os.path.join(labeled_revs_dir, 'sample3-features', 'rev_id_2020-08-01T05:40:00Z.txt')\n",
    "rev_id_list = pd.read_csv(revid_filepath, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(rev_id_list) == len(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31976/5992682 [00:00<00:18, 319754.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded revert data in 0:00:32.754740.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5992682/5992682 [00:21<00:00, 282831.12it/s]\n",
      "100%|██████████| 5331414/5331414 [00:27<00:00, 191148.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read the revert info\n",
    "# This dataframe contains additional data beyond what is in the rev_df\n",
    "s = datetime.now()\n",
    "stub_history_reverts_dir = os.path.join(derived_data_dir, 'stub-history-reverts')\n",
    "revert_df_filepath = os.path.join(stub_history_reverts_dir, 'revert_df.pkl')\n",
    "revert_df = pd.read_pickle(revert_df_filepath)\n",
    "print(f\"Loaded revert data in {datetime.now() - s}.\")\n",
    "\n",
    "# The most important info in the `revert_df` that isn't in the `rev_df` is the username info, which enables the identification of self-reverts.\n",
    "# `revert_df` has one line per **revert** revision, compared to the `rev_df` which has one line per revision.\n",
    "\n",
    "# identify self-reverts\n",
    "is_self_revert_list = []\n",
    "for row in tqdm(revert_df.itertuples(), total=len(revert_df)):\n",
    "    is_self_revert = row.reverting_user_text in row.reverted_user_texts\n",
    "    is_self_revert_list.append(is_self_revert)\n",
    "revert_df['is_self_revert'] = is_self_revert_list\n",
    "\n",
    "# now compute the outcome, which is a variant of `rev_df.is_reverted`\n",
    "reverted_rev_ids = set()\n",
    "# only count it as a reverted revision if it was not a self-revert\n",
    "# and it was reverted within one week\n",
    "threshold = 60 * 60 * 24 * 7 \n",
    "rs = revert_df[~revert_df.is_self_revert]\n",
    "for row in tqdm(rs.itertuples(), total=len(rs)):\n",
    "    reverting_timestamp = row.reverting_timestamp\n",
    "    for rev_id, timestamp in zip(row.reverted_rev_ids, row.reverted_timestamps):\n",
    "        if reverting_timestamp - timestamp <= threshold:\n",
    "            reverted_rev_ids.add(rev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>857219031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>857219035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>857219034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>857219036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>857219037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0  857219031\n",
       "1  857219035\n",
       "2  857219034\n",
       "3  857219036\n",
       "4  857219037"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_id_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11738345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #### Create the actual outcome variable and add it to the features dataframe\n",
    "# `features_df` contains only the features, not the revision ids. We create a binary outcome column based on the order of the revisions as they were read from the cache (and stored in `cache_rev_id_list`).\n",
    "\n",
    "is_reverted = [rev_id in reverted_rev_ids for rev_id in rev_id_list.iloc[:,0]]\n",
    "len(rev_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['is_reverted'] = is_reverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "\n",
    "# scale X vars\n",
    "X_test = sklearn.preprocessing.scale(features_df.iloc[:,:-1])\n",
    "\n",
    "# load model from file\n",
    "md = load('GB3.joblib')\n",
    "\n",
    "# predict on new data\n",
    "s = datetime.now()\n",
    "y_pred_test_calib = md.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(f\"Prediction completed in {datetime.now() - s}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction results\n",
    "pred_results = pd.DataFrame()\n",
    "pred_results['test_calib'] = y_pred_test_calib\n",
    "pred_results['test_label'] = np.array(features_df['is_reverted'])\n",
    "print(pred_results.head())\n",
    "    \n",
    "results_filepath = os.path.join('/export/scratch2/wastv004/wiki-ores-feedback/', 'prediction_2020-08-01.pkl')\n",
    "pred_results.to_pickle(results_filepath)\n",
    "print(results_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flagon Python3",
   "language": "python",
   "name": "flagon-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
