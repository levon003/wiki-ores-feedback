{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Feature Classification\n",
    "===\n",
    "\n",
    "Text feature classification of reverts. Messing around with large linear models of text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import bz2\n",
    "import sqlite3\n",
    "import difflib\n",
    "import gzip\n",
    "import json\n",
    "import base64\n",
    "import pickle\n",
    "import re\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import nltk\n",
    "import scipy.stats\n",
    "import para\n",
    "from itertools import groupby\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deltas\n",
    "from deltas.tokenizers import wikitext_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import sklearn.calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/export/scratch2/levon003/repos/wiki-ores-feedback'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = git_root_dir[0]\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/export/scratch2/wiki_data',\n",
       " '/export/scratch2/levon003/repos/wiki-ores-feedback/data/derived')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_dir = \"/export/scratch2/wiki_data\"\n",
    "derived_data_dir = os.path.join(git_root_dir, \"data\", \"derived\")\n",
    "raw_data_dir, derived_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/export/scratch2/levon003/repos/wiki-ores-feedback/data/derived/stub-history-all-revisions'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stub_history_dir = os.path.join(derived_data_dir, 'stub-history-all-revisions')\n",
    "stub_history_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/export/scratch2/levon003/repos/wiki-ores-feedback/data/derived/audit'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision_sample_dir = os.path.join(derived_data_dir, 'revision_sample')\n",
    "working_dir = os.path.join(derived_data_dir, 'audit')\n",
    "working_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3 data loaded in 0:00:28.522013.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33964442"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the sample dataframe\n",
    "s = datetime.now()\n",
    "revision_sample_dir = os.path.join(derived_data_dir, 'revision_sample')\n",
    "sample3_filepath = os.path.join(revision_sample_dir, 'sample3_all.pkl')\n",
    "rev_df = pd.read_pickle(sample3_filepath)\n",
    "print(f\"Sample 3 data loaded in {datetime.now() - s}.\")\n",
    "len(rev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>rev_id</th>\n",
       "      <th>rev_timestamp</th>\n",
       "      <th>is_revert_target</th>\n",
       "      <th>is_reverted</th>\n",
       "      <th>is_reverting</th>\n",
       "      <th>is_sample_eligible</th>\n",
       "      <th>prev_rev_id</th>\n",
       "      <th>next_rev_id</th>\n",
       "      <th>prev_rev_timestamp</th>\n",
       "      <th>next_rev_timestamp</th>\n",
       "      <th>reverted_rev_ids</th>\n",
       "      <th>reverting_rev_id</th>\n",
       "      <th>reverting_rev_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>818613649</td>\n",
       "      <td>1515102279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>818611292</td>\n",
       "      <td>818624114</td>\n",
       "      <td>1515101356</td>\n",
       "      <td>1515106953</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>818624114</td>\n",
       "      <td>1515106953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>818613649</td>\n",
       "      <td>820024812</td>\n",
       "      <td>1515102279</td>\n",
       "      <td>1515798752</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>820024812</td>\n",
       "      <td>1515798752</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>818624114</td>\n",
       "      <td>820025687</td>\n",
       "      <td>1515106953</td>\n",
       "      <td>1515799060</td>\n",
       "      <td>[]</td>\n",
       "      <td>820025687</td>\n",
       "      <td>1515799060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>820025687</td>\n",
       "      <td>1515799060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>820024812</td>\n",
       "      <td>820703495</td>\n",
       "      <td>1515798752</td>\n",
       "      <td>1516095884</td>\n",
       "      <td>[820024812]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>820703495</td>\n",
       "      <td>1516095884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>820025687</td>\n",
       "      <td>821673418</td>\n",
       "      <td>1515799060</td>\n",
       "      <td>1516597634</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id     rev_id  rev_timestamp  is_revert_target  is_reverted  \\\n",
       "1       12  818613649     1515102279                 0            0   \n",
       "2       12  818624114     1515106953                 1            0   \n",
       "3       12  820024812     1515798752                 0            1   \n",
       "4       12  820025687     1515799060                 0            0   \n",
       "5       12  820703495     1516095884                 0            0   \n",
       "\n",
       "   is_reverting  is_sample_eligible  prev_rev_id  next_rev_id  \\\n",
       "1             0                True    818611292    818624114   \n",
       "2             0                True    818613649    820024812   \n",
       "3             0                True    818624114    820025687   \n",
       "4             1                True    820024812    820703495   \n",
       "5             0                True    820025687    821673418   \n",
       "\n",
       "   prev_rev_timestamp  next_rev_timestamp reverted_rev_ids  reverting_rev_id  \\\n",
       "1          1515101356          1515106953               []                -1   \n",
       "2          1515102279          1515798752               []                -1   \n",
       "3          1515106953          1515799060               []         820025687   \n",
       "4          1515798752          1516095884      [820024812]                -1   \n",
       "5          1515799060          1516597634               []                -1   \n",
       "\n",
       "   reverting_rev_timestamp  \n",
       "1                       -1  \n",
       "2                       -1  \n",
       "3               1515799060  \n",
       "4                       -1  \n",
       "5                       -1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_dir = os.path.join(derived_data_dir, 'audit')\n",
    "text_db_filepath = os.path.join(audit_dir, 'text_2020-07-23T13:08:38Z.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db(db_filename):\n",
    "    db = sqlite3.connect(\n",
    "            db_filename,\n",
    "            detect_types=sqlite3.PARSE_DECLTYPES\n",
    "        )\n",
    "    db.row_factory = sqlite3.Row\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1106018/1106018 [02:53<00:00, 6362.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1106018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text_dict_list = []\n",
    "rev_id_content_dict = {}\n",
    "rev_id_comment_dict = {}\n",
    "try:\n",
    "    db = get_db(text_db_filepath)\n",
    "    cursor = db.execute(\"SELECT rev_id, content, comment FROM revisionText\")\n",
    "    for result in tqdm(cursor, total=1106018):\n",
    "        rev_id = result['rev_id']\n",
    "        rev_id_content_dict[rev_id] = result['content']\n",
    "        rev_id_comment_dict[rev_id] = result['comment']\n",
    "        #comment = result['comment']\n",
    "        #content = result['content']\n",
    "        #text_dict_list.append({\n",
    "        #    'rev_id': rev_id,\n",
    "        #    'content': content,\n",
    "        #    'comment': comment\n",
    "        #})\n",
    "finally:\n",
    "    db.close()\n",
    "len(rev_id_content_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_df = pd.DataFrame(text_dict_list)\n",
    "#print(len(text_df))\n",
    "#text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add text availability to sample3 revision data\n",
    "\n",
    "Either join in a dataframe with the text data or just record which entries have text available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.merge(rev_df, text_df, how='left', on='rev_id')\n",
    "df = rev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106018, 0.032563997371133024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['has_text'] = ~df.content.isna()\n",
    "df['has_text'] = df.rev_id.map(lambda rev_id: rev_id in rev_id_content_dict)\n",
    "np.sum(df.has_text), np.sum(df.has_text) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_ids_with_text = set(df[df.has_text].rev_id)\n",
    "df['prev_rev_has_text'] = df.prev_rev_id.map(lambda rev_id: rev_id in rev_ids_with_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996951, 0.029352786069619517)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.prev_rev_has_text), np.sum(df.prev_rev_has_text) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689050"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((df.prev_rev_has_text)&(df.has_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mess around with creating some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689050"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[(df.prev_rev_has_text)&(df.has_text)]\n",
    "len(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154493, 154373)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_rev_id = sdf.iloc[0].prev_rev_id\n",
    "curr_rev_id = sdf.iloc[0].rev_id\n",
    "prev_content = rev_id_content_dict[prev_rev_id]\n",
    "curr_content = rev_id_content_dict[curr_rev_id]\n",
    "len(prev_content), len(curr_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_tokens = wikitext_split.tokenize(prev_content)\n",
    "curr_tokens = wikitext_split.tokenize(curr_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5439, 5439, 5439)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = Counter(curr_tokens)\n",
    "curr_counter = Counter(curr_tokens)\n",
    "prev_counter = Counter(prev_tokens)\n",
    "diff.subtract(prev_counter)\n",
    "len(diff), len(curr_counter), len(prev_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Token(' ', type='whitespace')\t-18\n",
      "                  Token('\"', type='etc')\t-2\n",
      "           Token('(', type='paren_open')\t-1\n",
      "          Token(')', type='paren_close')\t-1\n",
      "            Token('2018', type='number')\t-1\n",
      "                Token('or', type='word')\t-1\n",
      "                Token('is', type='word')\t-1\n",
      "              Token('with', type='word')\t-1\n",
      "                Token(',', type='comma')\t-1\n",
      "         Token('treatment', type='word')\t-1\n",
      "              Token('some', type='word')\t-1\n",
      "          Token('children', type='word')\t-1\n",
      "               Token('ASD', type='word')\t-1\n",
      "            Token('review', type='word')\t-1\n",
      "                Token('to', type='word')\t-1\n",
      "              Token('that', type='word')\t-1\n",
      "                Token('an', type='word')\t-1\n",
      "        Token('considered', type='word')\t-1\n",
      "              Token('very', type='word')\t-1\n",
      "               Token('low', type='word')\t-1\n",
      "         Token('effective', type='word')\t-1\n",
      "         Token('According', type='word')\t-1\n",
      "              Token('EIBI', type='word')\t-1\n",
      "          Token('Cochrane', type='word')\t-1\n"
     ]
    }
   ],
   "source": [
    "for token, count in diff.items():\n",
    "    if count != 0:\n",
    "        print(f\"{repr(token):>40}\\t{count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8262/689050 [08:29<11:39:33, 16.22it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_id_tokens_dict = {}\n",
    "c = 0\n",
    "MAX_TEXTS = 10000\n",
    "for row in tqdm(sdf.itertuples(), total=len(sdf)):\n",
    "    prev_rev_id = row.prev_rev_id\n",
    "    curr_rev_id = row.rev_id\n",
    "    if prev_rev_id not in rev_id_tokens_dict:\n",
    "        prev_content = rev_id_content_dict[prev_rev_id]\n",
    "        rev_id_tokens_dict[prev_rev_id] = wikitext_split.tokenize(prev_content)\n",
    "        c += 1\n",
    "    if curr_rev_id not in rev_id_tokens_dict:\n",
    "        curr_content = rev_id_content_dict[curr_rev_id]\n",
    "        rev_id_tokens_dict[curr_rev_id] = wikitext_split.tokenize(curr_content)\n",
    "        c += 1\n",
    "    if c >= MAX_TEXTS:\n",
    "        break\n",
    "len(rev_id_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10001/10001 [00:45<00:00, 219.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "608805"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "for rev_id, tokens in tqdm(rev_id_tokens_dict.items(), total=len(rev_id_tokens_dict)):\n",
    "    word_counts.update(tokens)\n",
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Token(' ', type='whitespace'), 96745876),\n",
       " (Token('|', type='bar'), 12301610),\n",
       " (Token('=', type='equals'), 7189727),\n",
       " (Token(',', type='comma'), 6356344),\n",
       " (Token('.', type='period'), 5404204),\n",
       " (Token('the', type='word'), 4853522),\n",
       " (Token(']]', type='dbrack_close'), 4727430),\n",
       " (Token('[[', type='dbrack_open'), 4727351),\n",
       " (Token('of', type='word'), 3405190),\n",
       " (Token('\\n', type='whitespace'), 3273284),\n",
       " (Token('-', type='etc'), 2802844),\n",
       " (Token('and', type='word'), 2526688),\n",
       " (Token('}}', type='dcurly_close'), 1947002),\n",
       " (Token('{{', type='dcurly_open'), 1945417),\n",
       " (Token('in', type='word'), 1931983),\n",
       " (Token(\"''\", type='italic'), 1592096),\n",
       " (Token('to', type='word'), 1584792),\n",
       " (Token('\"', type='etc'), 1481191),\n",
       " (Token(')', type='paren_close'), 1379058),\n",
       " (Token('(', type='paren_open'), 1377848)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50895"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1 for v in word_counts.values() if v >= 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689050/689050 [00:02<00:00, 263890.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8263"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_rev_ids = set()\n",
    "for row in tqdm(sdf.itertuples(), total=len(sdf)):\n",
    "    prev_rev_id = row.prev_rev_id\n",
    "    curr_rev_id = row.rev_id\n",
    "    if prev_rev_id in rev_id_tokens_dict and curr_rev_id in rev_id_tokens_dict:\n",
    "        labeled_rev_ids.add(curr_rev_id)\n",
    "len(labeled_rev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_rev_id_dict = {row.rev_id: row.prev_rev_id for row in sdf.itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50895"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = len([1 for v in word_counts.values() if v >= 100])\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50895"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index_dict = {tup[0]: i for i, tup in enumerate(word_counts.most_common(n_features))}\n",
    "len(token_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8263/8263 [01:28<00:00, 93.58it/s] \n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(labeled_rev_ids),n_features))\n",
    "for row, curr_rev_id in tqdm(enumerate(labeled_rev_ids), total=len(labeled_rev_ids)):\n",
    "    prev_rev_id = prev_rev_id_dict[rev_id]\n",
    "    prev_tokens = rev_id_tokens_dict[prev_rev_id]\n",
    "    curr_tokens = rev_id_tokens_dict[curr_rev_id]\n",
    "    diff = Counter(curr_tokens)\n",
    "    prev_counter = Counter(prev_tokens)\n",
    "    diff.subtract(prev_counter)\n",
    "    \n",
    "    for token, count in diff.items():\n",
    "        if count != 0 and word_counts[token] >= 100:\n",
    "            X[row,token_index_dict[token]] = count\n",
    "    X[row,:] /= max(len(curr_tokens), len(prev_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8263, 50895)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8263,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_reverted_dict = {row.rev_id: row.is_reverted == 1 for row in sdf.itertuples()}\n",
    "y = np.array([is_reverted_dict[rev_id] for rev_id in labeled_rev_ids])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 0.19351325184557666)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y), np.sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382788226"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9102185867525333"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 91% of entries are 0\n",
    "382788226 / (8263 * 50895)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    solver='lbfgs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.20, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "0:00:05.927926\n"
     ]
    }
   ],
   "source": [
    "s = datetime.now()\n",
    "print(clf)\n",
    "\n",
    "    \n",
    "# train the model\n",
    "md = clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"{datetime.now() - s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the model\n",
    "y_pred_test = md.predict(X_test)\n",
    "y_pred_test_proba = md.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8039927404718693"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test == y_pred_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5690635769956061"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc = sklearn.metrics.roc_auc_score(y_test, y_pred_test_proba)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/scratch2/levon003/bin/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the vocabulary on all of the text documents\n",
    "# this should only include TRAINING documents, not TESTING documents\n",
    "s = datetime.now()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        max_features=40000\n",
    "    )\n",
    "\n",
    "count_vectorizer.fit(rev_id_tokens_dict.values())\n",
    "print(f\"{datetime.now() - s}\")\n",
    "\n",
    "# this is the size of the vocabulary\n",
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8263/8263 [00:00<00:00, 474916.88it/s]\n"
     ]
    }
   ],
   "source": [
    "X_docs = []\n",
    "for curr_rev_id in tqdm(labeled_rev_ids):\n",
    "    X_docs.append(rev_id_tokens_dict[curr_rev_id])\n",
    "X = count_vectorizer.transform(X_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.231109\n"
     ]
    }
   ],
   "source": [
    "s = datetime.now()\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(X)\n",
    "print(f\"{datetime.now() - s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:03.295813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/scratch2/levon003/bin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.20, random_state=500)\n",
    "s = datetime.now()\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000\n",
    ")\n",
    "    \n",
    "# train the model\n",
    "md = clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"{datetime.now() - s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09618874773139746, 0.7900786448880823, 0.7026598017631376)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = md.predict(X_test)\n",
    "y_pred_test_proba = md.predict_proba(X_test)[:,1]\n",
    "\n",
    "pct_predicted_reverted = np.sum(y_pred_test) / len(y_pred_test)\n",
    "test_acc = np.sum(y_test == y_pred_test) / len(y_test)\n",
    "roc_auc = sklearn.metrics.roc_auc_score(y_test, y_pred_test_proba)\n",
    "pct_predicted_reverted, test_acc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x40000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2918 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flagon Python3",
   "language": "python",
   "name": "flagon-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
